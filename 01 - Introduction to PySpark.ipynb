{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6fa433",
   "metadata": {},
   "source": [
    "## Import all the libraries needed for this notebook\n",
    "PySpark is the Python API for Apache Spark. It enables you to perform real-time, large-scale data processing in a distributed environment using Python. It also provides a PySpark shell for interactively analyzing your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad4d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Miscellaneous operating system interfaces \n",
    "import sys  # System-specific parameters and functions (https://docs.python.org/3/library/sys.html)\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Eclipse Adoptium\\jdk-17.0.18.8-hotspot\"  # Access Java OpenJDK installation path\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Import SparkSession from pyspark.sql module to create a Spark session\n",
    "from pyspark.sql import SparkSession  # The entry point to programming Spark with the Dataset and DataFrame API\n",
    "\n",
    "# Import the necessary types as classes\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1630df49",
   "metadata": {},
   "source": [
    "## Creating a DataFrame from filestores\n",
    "**About DataFrames**\n",
    "\n",
    "- DataFrames: Tabular format (rows/columns).\n",
    "- Support SQL-Like operations.\n",
    "- Comparable to a Pandas Dataframe or a SQL TABLE.\n",
    "- Structured Data.\n",
    "\n",
    "**Difference between Pandas and PySpark Dataframe**\n",
    "- Pandas operates on a single computer instance.\n",
    "\n",
    "PySpark distribute data across multiple instances. Afecting processing speed and scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064f1483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "root\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|     2020|              EN|             FT| Azure Data Engineer|100000|            USD|       100000|                MU|           0|              MU|           S|\n",
      "|     2020|              EN|             CT|  Staff Data Analyst| 60000|            CAD|        44753|                CA|          50|              CA|           L|\n",
      "|     2020|              SE|             FT|Staff Data Scientist|164000|            USD|       164000|                US|          50|              US|           M|\n",
      "|     2020|              EN|             FT|        Data Analyst| 42000|            EUR|        47899|                DE|           0|              DE|           L|\n",
      "|     2020|              EX|             FT|      Data Scientist|300000|            USD|       300000|                US|         100|              US|           L|\n",
      "|     2020|              MI|             CT|  Sales Data Analyst| 60000|            USD|        60000|                NG|           0|              NG|           M|\n",
      "|     2020|              EX|             FT|  Staff Data Analyst| 15000|            USD|        15000|                NG|           0|              CA|           M|\n",
      "|     2020|              MI|             FT|Business Data Ana...| 95000|            USD|        95000|                US|           0|              US|           M|\n",
      "|     2020|              EN|             FT|        Data Analyst| 20000|            EUR|        22809|                PT|         100|              PT|           M|\n",
      "|     2020|              EN|             FT|      Data Scientist| 43200|            EUR|        49268|                DE|           0|              DE|           S|\n",
      "|     2020|              SE|             FT|Machine Learning ...|157000|            CAD|       117104|                CA|          50|              CA|           L|\n",
      "|     2020|              EN|             FT|       Data Engineer| 48000|            EUR|        54742|                PK|         100|              DE|           L|\n",
      "|     2020|              MI|             FT|Product Data Analyst| 20000|            USD|        20000|                HN|           0|              HN|           S|\n",
      "|     2020|              MI|             FT|       Data Engineer| 51999|            EUR|        59303|                DE|         100|              DE|           S|\n",
      "|     2020|              EN|             FT|   Big Data Engineer| 70000|            USD|        70000|                US|         100|              US|           L|\n",
      "|     2020|              SE|             FT|      Data Scientist| 60000|            EUR|        68428|                GR|         100|              US|           L|\n",
      "|     2020|              MI|             FT|  Research Scientist|450000|            USD|       450000|                US|           0|              US|           M|\n",
      "|     2020|              MI|             FT|        Data Analyst| 41000|            EUR|        46759|                FR|          50|              FR|           L|\n",
      "|     2020|              MI|             FT|       Data Engineer| 65000|            EUR|        74130|                AT|          50|              AT|           L|\n",
      "|     2020|              MI|             FT|      Data Scientist|103000|            USD|       103000|                US|         100|              US|           L|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"MySparkAPP\").getOrCreate()\n",
    "print(\"Success\") # Print a success message to indicate that the Spark session has been created successfully\n",
    "\n",
    "# Create a DataFrame from a local CSV file with header and inferSchema options enabled\n",
    "salaries_df = spark.read.csv(\"data/salaries.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the schema of the DataFrame to understand the structure of the data\n",
    "salaries_df.printSchema()\n",
    "\n",
    "# Show the DataFrame\n",
    "salaries_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5dfec6",
   "metadata": {},
   "source": [
    "## Basic Analytics on PySpark Dataframes\n",
    "**Aggregate functions:**\n",
    "- count()\n",
    "- sum()\n",
    "- min()\n",
    "- max()\n",
    "\n",
    "**Key functions for PySpark analytics**\n",
    "- **.select()**: Selects specific columns from the DataFrame\n",
    "- **.filter():** Filters rows based on specific conditions\n",
    "- **.groupBy():** Groups rows based on one or more columns\n",
    "- **.agg():** Applies aggregate functions to grouped data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64368274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the DataFrame: 37234\n",
      "+----------------+------------------+\n",
      "|company_location|avg(salary_in_usd)|\n",
      "+----------------+------------------+\n",
      "|              QA|          300000.0|\n",
      "|              SK|          225000.0|\n",
      "|              VE|          192500.0|\n",
      "|              PR|          167500.0|\n",
      "|              US| 165911.9742057623|\n",
      "|              IL|        157888.625|\n",
      "|              CA| 143228.7273542601|\n",
      "|              SA|139999.33333333334|\n",
      "|              EG| 136903.7037037037|\n",
      "|              CH|130909.36363636363|\n",
      "|              AU|128938.14942528735|\n",
      "|              NZ|          127998.5|\n",
      "|              MX|117452.03448275862|\n",
      "|              DE|110896.81879194631|\n",
      "|              JP|        110821.625|\n",
      "|              IE|109723.14285714286|\n",
      "|              BE|          105576.5|\n",
      "|              UA|          103000.0|\n",
      "|              DZ|          100000.0|\n",
      "|              CN|          100000.0|\n",
      "+----------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the DataFrame and print the result\n",
    "row_count = salaries_df.count()\n",
    "print(f\"Total number of rows in the DataFrame: {row_count}\")\n",
    "\n",
    "# Sum the values in the \"salary_in_usd\" column and print the total salary\n",
    "total_salary_df = salaries_df.groupBy(\"company_location\").agg({\"salary_in_usd\": \"avg\"}).sort(\"avg(salary_in_usd)\", ascending=False)\n",
    "total_salary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3bb96",
   "metadata": {},
   "source": [
    "## More on Spark DataFrames\n",
    "**Creating DataFrames from various data sources:**\n",
    "- **CSV Files:** Common for structured, delimited data. Don't define or enforce data type or schema. Leading to potencial incosistency.\n",
    "- **JSON Files:** Semi-structured, hierarchiecal data format. However, can be storage insentive.\n",
    "- **Parquet Files:** Optimized for storage and querying, often used in data engineering. Enforces schema definition and support complex data structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c473fb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------+--------------+-----------------+\n",
      "|age|education.num|income|marital.status|       occupation|\n",
      "+---+-------------+------+--------------+-----------------+\n",
      "| 90|            9| <=50K|       Widowed|                ?|\n",
      "| 82|            9| <=50K|       Widowed|  Exec-managerial|\n",
      "| 66|           10| <=50K|       Widowed|                ?|\n",
      "| 54|            4| <=50K|      Divorced|Machine-op-inspct|\n",
      "| 41|           10| <=50K|     Separated|   Prof-specialty|\n",
      "| 34|            9| <=50K|      Divorced|    Other-service|\n",
      "| 38|            6| <=50K|     Separated|     Adm-clerical|\n",
      "| 74|           16|  >50K| Never-married|   Prof-specialty|\n",
      "| 68|            9| <=50K|      Divorced|   Prof-specialty|\n",
      "| 41|           10|  >50K| Never-married|     Craft-repair|\n",
      "| 45|           16|  >50K|      Divorced|   Prof-specialty|\n",
      "| 38|           15|  >50K| Never-married|   Prof-specialty|\n",
      "| 52|           13|  >50K|       Widowed|    Other-service|\n",
      "| 32|           14|  >50K|     Separated|  Exec-managerial|\n",
      "| 51|           16|  >50K| Never-married|                ?|\n",
      "| 46|           15|  >50K|      Divorced|   Prof-specialty|\n",
      "| 45|            7|  >50K|      Divorced| Transport-moving|\n",
      "| 57|           14|  >50K|      Divorced|  Exec-managerial|\n",
      "| 22|           12|  >50K| Never-married|Handlers-cleaners|\n",
      "| 34|           13|  >50K|     Separated|            Sales|\n",
      "+---+-------------+------+--------------+-----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Load JSON file into a DataFrame and show the contents\n",
    "adults_df = spark.read.json(\"data/adults.json\")\n",
    "\n",
    "adults_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a94346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+\n",
      "|   price| area|bedrooms|bathrooms|stories|mainroad|guestroom|basement|hotwaterheating|airconditioning|parking|prefarea|furnishingstatus|\n",
      "+--------+-----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+\n",
      "|13300000| 7420|       4|        2|      3|     yes|       no|      no|             no|            yes|      2|     yes|       furnished|\n",
      "|12250000| 8960|       4|        4|      4|     yes|       no|      no|             no|            yes|      3|      no|       furnished|\n",
      "|12250000| 9960|       3|        2|      2|     yes|       no|     yes|             no|             no|      2|     yes|  semi-furnished|\n",
      "|12215000| 7500|       4|        2|      2|     yes|       no|     yes|             no|            yes|      3|     yes|       furnished|\n",
      "|11410000| 7420|       4|        1|      2|     yes|      yes|     yes|             no|            yes|      2|      no|       furnished|\n",
      "|10850000| 7500|       3|        3|      1|     yes|       no|     yes|             no|            yes|      2|     yes|  semi-furnished|\n",
      "|10150000| 8580|       4|        3|      4|     yes|       no|      no|             no|            yes|      2|     yes|  semi-furnished|\n",
      "|10150000|16200|       5|        3|      2|     yes|       no|      no|             no|             no|      0|      no|     unfurnished|\n",
      "| 9870000| 8100|       4|        1|      2|     yes|      yes|     yes|             no|            yes|      2|     yes|       furnished|\n",
      "| 9800000| 5750|       3|        2|      4|     yes|      yes|      no|             no|            yes|      1|     yes|     unfurnished|\n",
      "| 9800000|13200|       3|        1|      2|     yes|       no|     yes|             no|            yes|      2|     yes|       furnished|\n",
      "| 9681000| 6000|       4|        3|      2|     yes|      yes|     yes|            yes|             no|      2|      no|  semi-furnished|\n",
      "| 9310000| 6550|       4|        2|      2|     yes|       no|      no|             no|            yes|      1|     yes|  semi-furnished|\n",
      "| 9240000| 3500|       4|        2|      2|     yes|       no|      no|            yes|             no|      2|      no|       furnished|\n",
      "| 9240000| 7800|       3|        2|      2|     yes|       no|      no|             no|             no|      0|     yes|  semi-furnished|\n",
      "| 9100000| 6000|       4|        1|      2|     yes|       no|     yes|             no|             no|      2|      no|  semi-furnished|\n",
      "| 9100000| 6600|       4|        2|      2|     yes|      yes|     yes|             no|            yes|      1|     yes|     unfurnished|\n",
      "| 8960000| 8500|       3|        2|      4|     yes|       no|      no|             no|            yes|      2|      no|       furnished|\n",
      "| 8890000| 4600|       3|        2|      2|     yes|      yes|      no|             no|            yes|      2|      no|       furnished|\n",
      "| 8855000| 6420|       3|        2|      2|     yes|       no|      no|             no|            yes|      1|     yes|  semi-furnished|\n",
      "+--------+-----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Load Parquet file into a DataFrame and show the contents\n",
    "house_prices_df = spark.read.parquet(\"data/house-price.parquet\")\n",
    "\n",
    "house_prices_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95518b53",
   "metadata": {},
   "source": [
    "## Shema inference and manual schema definition\n",
    "- Spark can infer schemas from data with inferShema=True\n",
    "- Manually define schema for better control - useful for fixed data structures\n",
    "\n",
    "## DataTypes in PySpark DataFrames\n",
    "- IntegerType: Whole numbers\n",
    "- LongType: Larger whole numbers (8-byte signed numbers)\n",
    "- FloatType and DoubleType: Floating-point numbers for decimal values\n",
    "- StringType: Used for text or string data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f24b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------------+\n",
      "| id| name|      scores|\n",
      "+---+-----+------------+\n",
      "|  1|Alice|[85, 90, 92]|\n",
      "|  2|  Bob|[78, 82, 88]|\n",
      "+---+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct the schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"scores\", ArrayType(IntegerType()), True)\n",
    "])\n",
    "\n",
    "# Set the schema\n",
    "df = spark.createDataFrame([(1, \"Alice\", [85, 90, 92]), (2, \"Bob\", [78, 82, 88])], schema)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9abd7",
   "metadata": {},
   "source": [
    "## Dataframes operations - selection and filtering\n",
    "- Use **.select()** to choose specific columns\n",
    "- Use **.filter()** or .where() to filter rows based on conditions\n",
    "- Use **.sort()** to order by a collection of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02bc1f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| area|bedrooms|\n",
      "+-----+--------+\n",
      "| 7420|       4|\n",
      "| 8960|       4|\n",
      "| 9960|       3|\n",
      "| 7500|       4|\n",
      "| 7420|       4|\n",
      "| 7500|       3|\n",
      "| 8580|       4|\n",
      "|16200|       5|\n",
      "| 8100|       4|\n",
      "| 5750|       3|\n",
      "|13200|       3|\n",
      "| 6000|       4|\n",
      "| 6550|       4|\n",
      "| 3500|       4|\n",
      "| 7800|       3|\n",
      "| 6000|       4|\n",
      "| 6600|       4|\n",
      "| 8500|       3|\n",
      "| 4600|       3|\n",
      "| 6420|       3|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "house_prices_df.select(\"area\", \"bedrooms\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a7a18a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+\n",
      "|  price|area|bedrooms|bathrooms|stories|mainroad|guestroom|basement|hotwaterheating|airconditioning|parking|prefarea|furnishingstatus|\n",
      "+-------+----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+\n",
      "|8400000|7950|       5|        2|      2|     yes|       no|     yes|            yes|             no|      2|      no|     unfurnished|\n",
      "|6440000|8580|       5|        3|      2|     yes|       no|      no|             no|             no|      2|      no|       furnished|\n",
      "+-------+----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "house_prices_df.where(house_prices_df[\"parking\"]==2).filter(house_prices_df[\"bedrooms\"]>4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c483ff0",
   "metadata": {},
   "source": [
    "## Sorting and dropping missing values\n",
    "- Order data using **.sort()** or **.orderBy()**\n",
    "- Use **na.drop()** to remove rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360f90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------+------------------+-----------------+\n",
      "|age|education.num|income|    marital.status|       occupation|\n",
      "+---+-------------+------+------------------+-----------------+\n",
      "| 90|            9| <=50K|           Widowed|                ?|\n",
      "| 82|            9| <=50K|           Widowed|  Exec-managerial|\n",
      "| 74|           16|  >50K|     Never-married|   Prof-specialty|\n",
      "| 73|            9| <=50K|Married-civ-spouse|  Farming-fishing|\n",
      "| 71|            9| <=50K|Married-civ-spouse|                ?|\n",
      "| 71|            9| <=50K|Married-civ-spouse|            Sales|\n",
      "| 68|            9| <=50K|          Divorced|   Prof-specialty|\n",
      "| 68|           10| <=50K|Married-civ-spouse|                ?|\n",
      "| 67|           10| <=50K|Married-civ-spouse|                ?|\n",
      "| 66|           10| <=50K|           Widowed|                ?|\n",
      "| 63|           16|  >50K|          Divorced|  Exec-managerial|\n",
      "| 62|           13|  >50K|Married-civ-spouse|  Farming-fishing|\n",
      "| 61|            9| <=50K|          Divorced|            Sales|\n",
      "| 61|            9| <=50K|Married-civ-spouse|                ?|\n",
      "| 60|            9|  >50K|     Never-married|  Exec-managerial|\n",
      "| 60|           11|  >50K|Married-civ-spouse|Machine-op-inspct|\n",
      "| 60|           15|  >50K|Married-civ-spouse|   Prof-specialty|\n",
      "| 59|            6|  >50K|           Widowed|  Exec-managerial|\n",
      "| 58|           10|  >50K|Married-civ-spouse|  Farming-fishing|\n",
      "| 57|           14|  >50K|          Divorced|  Exec-managerial|\n",
      "+---+-------------+------+------------------+-----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "adults_df.sort(\"age\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb152458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------+--------------+-----------------+\n",
      "|age|education_num|income|marital_status|       occupation|\n",
      "+---+-------------+------+--------------+-----------------+\n",
      "| 90|            9| <=50K|       Widowed|                ?|\n",
      "| 82|            9| <=50K|       Widowed|  Exec-managerial|\n",
      "| 66|           10| <=50K|       Widowed|                ?|\n",
      "| 54|            4| <=50K|      Divorced|Machine-op-inspct|\n",
      "| 41|           10| <=50K|     Separated|   Prof-specialty|\n",
      "| 34|            9| <=50K|      Divorced|    Other-service|\n",
      "| 38|            6| <=50K|     Separated|     Adm-clerical|\n",
      "| 74|           16|  >50K| Never-married|   Prof-specialty|\n",
      "| 68|            9| <=50K|      Divorced|   Prof-specialty|\n",
      "| 41|           10|  >50K| Never-married|     Craft-repair|\n",
      "| 45|           16|  >50K|      Divorced|   Prof-specialty|\n",
      "| 38|           15|  >50K| Never-married|   Prof-specialty|\n",
      "| 52|           13|  >50K|       Widowed|    Other-service|\n",
      "| 32|           14|  >50K|     Separated|  Exec-managerial|\n",
      "| 51|           16|  >50K| Never-married|                ?|\n",
      "| 46|           15|  >50K|      Divorced|   Prof-specialty|\n",
      "| 45|            7|  >50K|      Divorced| Transport-moving|\n",
      "| 57|           14|  >50K|      Divorced|  Exec-managerial|\n",
      "| 22|           12|  >50K| Never-married|Handlers-cleaners|\n",
      "| 34|           13|  >50K|     Separated|            Sales|\n",
      "+---+-------------+------+--------------+-----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Replace dots with underscores for all column names   \n",
    "for col_name in adults_df.columns:\n",
    "    if '.' in col_name:\n",
    "        new_name = col_name.replace('.', '_')\n",
    "        adults_df = adults_df.withColumnRenamed(col_name, new_name)\n",
    "\n",
    "# Drop rows with null values and show the resulting DataFrame\n",
    "adults_df.na.drop().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
